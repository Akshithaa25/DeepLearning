{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOTBjx7UxYjhIHWaThHTAlQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akshithaa25/DeepLearning/blob/main/DL_2348502_Prg_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "3# https://towardsdatascience.com/perceptrons-logical-functions-and-the-xor-problem-37ca5025790a"
      ],
      "metadata": {
        "id": "iX2pYsJ7P8OB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def unit_step(v):\n",
        "\tif v >= 0:\n",
        "\t\treturn 1\n",
        "\telse:\n",
        "\t\treturn 0\n",
        "\n",
        "def perceptron(x, w, b):\n",
        "\t# \"\"\" Function implemented by a perceptron with\n",
        "\t\t# weight vector w and bias b \"\"\"\n",
        "\tv = np.dot(w, x) + b\n",
        "\ty = unit_step(v)\n",
        "\treturn y"
      ],
      "metadata": {
        "id": "GGDtj8i0TohZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def AND_percep(x):\n",
        "    w = np.array([1, 1])\n",
        "    b = -1.5\n",
        "    return perceptron(x, w, b)\n",
        "\n",
        "# Test\n",
        "example1 = np.array([1, 1])\n",
        "example2 = np.array([1, 0])\n",
        "example3 = np.array([0, 1])\n",
        "example4 = np.array([0, 0])\n",
        "\n",
        "print(\"AND({}, {}) = {}\".format(1, 1, AND_percep(example1)))\n",
        "print(\"AND({}, {}) = {}\".format(1, 0, AND_percep(example2)))\n",
        "print(\"AND({}, {}) = {}\".format(0, 1, AND_percep(example3)))\n",
        "print(\"AND({}, {}) = {}\".format(0, 0, AND_percep(example4)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJTyho_LRdvC",
        "outputId": "864c9c43-51af-4fac-ca32-64d9798aa2d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AND(1, 1) = 1\n",
            "AND(1, 0) = 0\n",
            "AND(0, 1) = 0\n",
            "AND(0, 0) = 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A \"single-layer\" perceptron can't implement XOR. The reason is because the classes in XOR are not linearly separable."
      ],
      "metadata": {
        "id": "TzhUWP57WwRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://mylearningsinaiml.wordpress.com/deep-learning/dl4cv/perceptron-algorithm/\n"
      ],
      "metadata": {
        "id": "ndlQNAzJUDdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y8hFNgkmZPcF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}